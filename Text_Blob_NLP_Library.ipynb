{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS/eHT2i7FhY078cBUXHMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KODURISRIHARI/Text_Blob_NLP_Tool/blob/main/Text_Blob_NLP_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TfAuoQtSU7yI"
      },
      "outputs": [],
      "source": [
        "import textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "0Z02xc31VH5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TextBlob\n",
        "###Overview:\n",
        "- TextBlob is a Python library built on top of NLTK (Natural Language Toolkit).\n",
        "- Simplifies tasks like part-of-speech tagging, noun phrase extraction, and sentiment\n",
        "analysis.\n",
        "Key Sentiment Properties:\n",
        "- Polarity: Ranges from -1.0 to 1.0 (negative to positive).\n",
        "- Subjectivity: Ranges from 0.0 to 1.0 (objective to subjective)."
      ],
      "metadata": {
        "id": "PbEHoY6UVXQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txb = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n"
      ],
      "metadata": {
        "id": "W-DZzjSRVdWw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPHhJTwxWLpW",
        "outputId": "399e9bd8-908e-4bfe-a77d-616c208c0c1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sentiment Analysis¶\n"
      ],
      "metadata": {
        "id": "TnxlwifAXE-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
        "testimonial.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNX-hEuIWB7d",
        "outputId": "725c5866-c217-49ff-e82e-c1b542b4af1c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testimonial.sentiment.polarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJGMz2eyWpAC",
        "outputId": "08edf205-7131-4f72-b315-1855cb4d4212"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39166666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For instance, the NaiveBayesAnalyzer returns its result as a namedtuple of the form: Sentiment(classification, p_pos, p_neg)."
      ],
      "metadata": {
        "id": "ns1OK5z5Y7gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "\n",
        "blob = TextBlob(\"I love this library\", analyzer=NaiveBayesAnalyzer())\n",
        "blob.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rThTBJ2vY9r4",
        "outputId": "3260038d-fb7a-49d3-ded7-07d9f6eb9172"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(classification='pos', p_pos=0.7996209910191279, p_neg=0.2003790089808724)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization\n",
        "Break the textblobs into words or sentences"
      ],
      "metadata": {
        "id": "uXuQuys_XlO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zen = TextBlob(\"Beautiful is better than ugly. \"\n",
        "                \"Explicit is better than implicit. \"\n",
        "                \"Simple is better than complex.\")\n",
        "zen.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI05slDpXzZM",
        "outputId": "0d9b6e02-4ce1-4618-84ad-8868dc2d5e7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['Beautiful', 'is', 'better', 'than', 'ugly', 'Explicit', 'is', 'better', 'than', 'implicit', 'Simple', 'is', 'better', 'than', 'complex'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zen.sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fDjfOb-YCI-",
        "outputId": "426837f3-3629-4566-df06-1ca8c0c4fe05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence(\"Beautiful is better than ugly.\"),\n",
              " Sentence(\"Explicit is better than implicit.\"),\n",
              " Sentence(\"Simple is better than complex.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TabTokenizer()\n",
        "- If we have \\t or tab in the text , we use TabTokenizer"
      ],
      "metadata": {
        "id": "EmagX-azahPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.tokenize import TabTokenizer\n",
        "\n",
        "tokenizer = TabTokenizer()\n",
        "blob = TextBlob(\"This is\\ta rather tabby\\tblob.\", tokenizer=tokenizer)\n",
        "blob.tokens\n",
        "#WordList(['This is', 'a rather tabby', 'blob.'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB9A3IVMaCB0",
        "outputId": "65920d78-acf7-4212-edcb-636588825cc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['This is', 'a rather tabby', 'blob.'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BlanklineTokenizer()\n",
        "- If we have \\t or tab in the text , we use BlanklineTokenizer"
      ],
      "metadata": {
        "id": "_9R3NQpIa4Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.tokenize import BlanklineTokenizer\n",
        "\n",
        "tokenizer = BlanklineTokenizer()\n",
        "blob = TextBlob(\"A token\\n\\nof appreciation\")\n",
        "blob.tokenize(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "admCPgmobMGu",
        "outputId": "80e1ef88-9284-4e8b-e597-1892ad2365ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['A token', 'of appreciation'])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sentence objects have the same properties and methods as TextBlobs.\n",
        "\n"
      ],
      "metadata": {
        "id": "ltfk8YRQYE8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in zen.sentences:\n",
        "  print(sentence.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpMVJbR6YKPG",
        "outputId": "4210980d-595b-4550-b808-3921c7f6ee6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.2166666666666667, subjectivity=0.8333333333333334)\n",
            "Sentiment(polarity=0.5, subjectivity=0.5)\n",
            "Sentiment(polarity=0.06666666666666667, subjectivity=0.41904761904761906)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Words Inflection and Lemmatization"
      ],
      "metadata": {
        "id": "qkbq36o-YQYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful methods, e.g. for word inflection."
      ],
      "metadata": {
        "id": "CxOgLxkDjNys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = TextBlob('Use 4 spaces per indentation level.')\n",
        "print(sentence.words)\n",
        "print(sentence.words[2].singularize())\n",
        "print(sentence.words[-1].pluralize())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7_JqYftjR6u",
        "outputId": "f4b7e0e9-34f2-4810-fcec-0fe90f59b169"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Use', '4', 'spaces', 'per', 'indentation', 'level']\n",
            "space\n",
            "levels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words can be lemmatized by calling the lemmatize method."
      ],
      "metadata": {
        "id": "N3iyzqWSjg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "w = Word(\"octopi\")\n",
        "print(w.lemmatize())\n",
        "\n",
        "w = Word(\"went\")\n",
        "print(w.lemmatize(\"v\")) # Pass in WordNet part of speech (verb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aEXTyWPknsG",
        "outputId": "f5534898-f8e4-4dc7-da21-13aa8f456020"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "octopus\n",
            "go\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WordNet Integration\n",
        " - You can access the synsets for a Word via the synsets property or the get_synsets method, optionally passing in a part of speech"
      ],
      "metadata": {
        "id": "7V66D2Hsk2zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "from textblob.wordnet import VERB\n",
        "\n",
        "word1 = Word(\"octopus\")\n",
        "print(word1.synsets)\n",
        "print(Word(\"hack\").get_synsets(pos=VERB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdUM5851osz2",
        "outputId": "de1c0b1c-44fb-46f1-f01e-cab8256523e8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('octopus.n.01'), Synset('octopus.n.02')]\n",
            "[Synset('chop.v.05'), Synset('hack.v.02'), Synset('hack.v.03'), Synset('hack.v.04'), Synset('hack.v.05'), Synset('hack.v.06'), Synset('hack.v.07'), Synset('hack.v.08')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can access the definitions for each synset via the definitions property or the define() method, which can also take an optional part-of-speech argument."
      ],
      "metadata": {
        "id": "QXKnFm6Bo6Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Word(\"octopus\").definitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htCfC9jipLmQ",
        "outputId": "a8bb8b52-a763-42f5-b9fb-42e21b725802"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tentacles of octopus prepared as food',\n",
              " 'bottom-living cephalopod having a soft oval body with eight long tentacles']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#You can also create synsets directly\n",
        "from textblob.wordnet import Synset\n",
        "\n",
        "\n",
        "octopus = Synset('octopus.n.02')\n",
        "shrimp = Synset('shrimp.n.03')\n",
        "octopus.path_similarity(shrimp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTw0UBjgpNVz",
        "outputId": "c811fca7-31fe-49e7-c2f7-6a63585e46f9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WordLists\n",
        "A WordList is just a Python list with additional methods."
      ],
      "metadata": {
        "id": "3lj3Pty2pgmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "animals = TextBlob(\"cat dog octopus\")\n",
        "print(animals.words)\n",
        "print(animals.words.pluralize())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcHxHKK1pw_h",
        "outputId": "16f8f60f-18da-4755-8eed-85a48cd3d4da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog', 'octopus']\n",
            "['cats', 'dogs', 'octopodes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spelling Correction\n",
        " - Use the correct() method to attempt spelling correction."
      ],
      "metadata": {
        "id": "gAD2c2Fpp3kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = TextBlob(\"I havv goood speling!\")\n",
        "print(b.correct())\n",
        "b = TextBlob(\"I havv goood spailing!\")\n",
        "print(b.correct())\n",
        "b = TextBlob(\"I havv goood spiling!\")\n",
        "print(b.correct())\n",
        "b = TextBlob(\"I havv goood spoling!\")\n",
        "print(b.correct())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBc8Dau6qIEc",
        "outputId": "3033758d-c93e-4b3f-c1f4-1d588b63329c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have good spelling!\n",
            "I have good sailing!\n",
            "I have good smiling!\n",
            "I have good spoiling!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions."
      ],
      "metadata": {
        "id": "PsLziG17qJ7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "\n",
        "b = Word(\"spoling!\")\n",
        "print(b.spellcheck())\n",
        "print(\"\\n\")\n",
        "b = Word(\"spealing!\")\n",
        "print(b.spellcheck())\n",
        "print(\"\\n\")\n",
        "b = Word(\"spailing!\")\n",
        "print(b.spellcheck())\n",
        "print(\"\\n\")\n",
        "b = Word(\"spiling!\")\n",
        "print(b.spellcheck())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osIuz7PTqoxt",
        "outputId": "4485f33f-b1f7-4801-d49d-252f79d75e1b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('spoiling', 0.875), ('sporing', 0.125)]\n",
            "\n",
            "\n",
            "[('speaking', 0.925), ('sealing', 0.04), ('spelling', 0.02), ('stealing', 0.015)]\n",
            "\n",
            "\n",
            "[('sailing', 0.6190476190476191), ('spoiling', 0.3333333333333333), ('sailings', 0.047619047619047616)]\n",
            "\n",
            "\n",
            "[('smiling', 0.8655913978494624), ('sailing', 0.06989247311827956), ('spoiling', 0.03763440860215054), ('piling', 0.010752688172043012), ('spiking', 0.005376344086021506), ('soiling', 0.005376344086021506), ('sailings', 0.005376344086021506)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spelling correction is based on Peter Norvig’s “How to Write a Spelling Corrector”\n",
        "\n",
        "as implemented in the pattern library. It is about 70% accurate"
      ],
      "metadata": {
        "id": "5OzM0EYIqszs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Word and Noun Phrase Frequencies\n",
        "There are two ways to get the frequency of a word or noun phrase in a TextBlob.\n",
        "\n",
        "The first is through the word_counts dictionary."
      ],
      "metadata": {
        "id": "GvMfEAr0rsTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can specify whether or not the search should be case-sensitive (default is False)"
      ],
      "metadata": {
        "id": "g50xVTO6xI6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
        "                     \"We are now the Knights who say Ekki ekki ekki PTANG.\")\n",
        "print(monty.word_counts['we'])\n",
        "print(monty.words.count('ekki', case_sensitive=True))\n",
        "print(monty.words.count('ekki', case_sensitive=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmHMaiBWr3Z9",
        "outputId": "0d9bc734-72f7-4f17-ba31-dbc76cb3b780"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "print(monty.noun_phrases.count('ekki'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_wGe6kgr8Ml",
        "outputId": "c7735ec7-7060-46ab-acf7-5f9e0f432478"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The second way is to use the count() method.\n",
        "\n",
        "monty.words.count('ekki')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_t0u54ksm_k",
        "outputId": "9797aa9c-eac4-466f-db13-64442f4e9106"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parsing\n",
        " - Use the parse() method to parse the text.\n",
        "\n"
      ],
      "metadata": {
        "id": "vvzjS66fs4Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = TextBlob(\"And now for something completely different.\")\n",
        "print(b.parse())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhBHnKSzyVIQ",
        "outputId": "1dae5827-58ba-4177-980a-63276f961d47"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#n-grams\n",
        "The TextBlob.ngrams() method returns a list of tuples of n successive words."
      ],
      "metadata": {
        "id": "3AhD2JfByZVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob = TextBlob(\"Now is better than never.\")\n",
        "blob.ngrams(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ6hr7F40Rhv",
        "outputId": "bdf9065e-d157-475e-e1c6-a68c2efaaf1e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Now', 'is', 'better']),\n",
              " WordList(['is', 'better', 'than']),\n",
              " WordList(['better', 'than', 'never'])]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7bNOFBQc0TNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}